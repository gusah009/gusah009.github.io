{"componentChunkName":"component---src-templates-post-template-tsx","path":"/infra/2025-04-01-logstash OOM/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<blockquote>\n<p>오늘은 jdk11을 사용하는 logstash에서 발생한 OOM 이슈를 트러블슈팅한 경험에 대해 공유하겠습니다</p>\n</blockquote>\n<p>발단은 새로운 K8s 클러스터에 Logstash를 추가하면서부터였습니다.</p>\n<p>새로운 클러스터로 옮기면서 파이프라인도 하나 추가했는데요, 갑자기 예상과 다르게 logstash가 OOM을 발생시키면서 <strong>파드들이 모두 죽어나가기 시작했습니다.</strong></p>\n<p>기존에 있던 memory limits (1.5Gi)를 풀고 확인해보니 <strong>거의 3Gi를 차지하고 있었어요.</strong></p>\n<p>기존 클러스터의 logstash에서 파이프라인을 단 하나 추가했을 뿐인데 메모리를 너무 많이 잡아먹는게 이상해서 조사를 해봤습니다.</p>\n<blockquote>\n<p>기존 클러스터는 800Mi 정도 차지하고 있었어요.</p>\n</blockquote>\n<h2>1. 추가된 파이프라인 로직 의심</h2>\n<p>처음엔 당연히 추가된 파이프라인이 메모리를 아주 많이 사용하는 것으로 의심해 <strong>파이프라인을 분석</strong>해봤는데요.</p>\n<p>filter에서 필드 하나만 replace 하는 파이프라인이라 딱히 이상할 게 없어 보였습니다.</p>\n<h2>2. 힙 오버플로우 의심</h2>\n<p>다음으로 의심한 건 힙 메모리의 GC가 안돌았다거나, 무한히 커지는 객체가 있을까였습니다.</p>\n<p>그래서 heap dump를 떠서 IntelliJ로 확인해봤는데요, <strong>특별히 용량이 매우 큰 객체가 보이질 않았습니다.</strong></p>\n<p>여기서 정말 미궁에 빠졌는데요, 힙 메모리가 크지 않다면 <strong>도대체 어디서 메모리를 차지</strong>하고 있는걸까요?</p>\n<p>logstash가 아니라 서브 플러그인 같은 곳에서 메모리를 차지하고 있는데 잘못 짚고 있는 걸까 생각했습니다.</p>\n<h2>3. cgroup v2 의심</h2>\n<p>예전에도 사내에서 k8s 버전업을 진행하면서 <a href=\"https://gusah009.github.io/infra/2024-04-23-k8s%EC%97%90%EC%84%9C%20%EA%B5%AC%EB%B2%84%EC%A0%84%20jdk%EC%9D%98%20heap%20size%20%EC%84%A4%EC%A0%95%EC%9D%B4%20%EC%9D%B4%EC%83%81%ED%95%9C%20%EC%9D%B4%EC%8A%88/\" target=\"_blank\" rel=\"nofollow\">비슷한 이슈</a>를 트러블슈팅 했던 적이 있었는데요.</p>\n<p>갑자기 그 이슈가 떠올라서 cgroup을 확인해보았습니다.</p>\n<p><strong>예상대로</strong> 기존에 사용하던 k8s 클러스터의 노드와 신규 클러스터 노드의 <strong>cgroup 버전이 달랐습니다.</strong></p>\n<blockquote>\n<p>노드의 cgroup 버전이 올라갔는데 JDK 버전이 이를 따라가지 못하면 새로운 cgroup의 cpu, memory 파일을 찾지 못하는 문제가 있습니다.</p>\n<p>컨테이너의 최대 cpu, memory를 찾지 못한 컨테이너는 <strong>노드 전체의 cpu, memory</strong>를 사용하게 됩니다.</p>\n</blockquote>\n<h3>3-1. heap size 의심</h3>\n<p>처음엔 기존 이슈처럼 힙 메모리를 의심했습니다.</p>\n<p>하지만 저희가 띄운 logstash는 힙 메모리를 퍼센티지가 아니라 <code class=\"language-text\">-Xms</code>, <code class=\"language-text\">-Xmx</code> 옵션으로 정확히 잡고 있었습니다.</p>\n<p>JDK11 코드를 뒤져보면서 cgroup을 못찾으면 Xms, Xmx 설정을 무시하는 코드가 있지 않을까 <strong>아무리 살펴봤지만 찾지 못했습니다.</strong></p>\n<p>코드 분석을 잠시 멈추고 다시 원점으로 돌아갔습니다.</p>\n<p>우선 진짜 힙 메모리를 정상적으로 사용중인지 확인하기 위해 <strong>jcmd라는 툴을 이용해 메모리를 분석</strong>해보았습니다.</p>\n<pre class=\"grvsc-container default-dark\" data-language=\"sh\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">-      Java Heap (reserved=524288KB, committed=524288KB)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (mmap: reserved=524288KB, committed=524288KB)</span></span></span></code></pre>\n<p>확인해보니 Java Heap은 정상적으로 500MB를 할당해 사용중이었습니다.</p>\n<h3>3-2. 수상한 thread 사용량</h3>\n<p>그래도 메모리 분석을 통해 <strong>의심스러운 부분을 하나 발견</strong>할 수 있었는데, 바로 Thread 사용량이었습니다. (약 1.1G)</p>\n<pre class=\"grvsc-container default-dark\" data-language=\"sh\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">-      Thread (reserved=1138195KB, committed=151639KB)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (thread </span><span class=\"mtk3\">#1103)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (stack: reserved=1132900KB, committed=146344KB)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (malloc=4016KB </span><span class=\"mtk3\">#6620)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (arena=1279KB </span><span class=\"mtk3\">#2192)</span></span></span></code></pre>\n<p>정상적인 logstash라면 스레드 사용량은 아래와 같습니다.</p>\n<pre class=\"grvsc-container default-dark\" data-language=\"sh\" data-index=\"2\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">-      Thread (reserved=270655KB, committed=28975KB)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (thread </span><span class=\"mtk3\">#263)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (stack: reserved=269396KB, committed=27716KB)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (malloc=952KB </span><span class=\"mtk3\">#1580)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">       (arena=307KB </span><span class=\"mtk3\">#525)</span></span></span></code></pre>\n<p>스레드 사용량에서 큰 차이가 나는걸 확인할 수 있었고, 이상함을 느껴서 jstack이라는 툴로 스레드 사용률을 확인해보았습니다.</p>\n<pre class=\"grvsc-container default-dark\" data-language=\"sh\" data-index=\"3\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">./jstack 1 | grep </span><span class=\"mtk8\">&#39;^&quot;&#39;</span><span class=\"mtk1\"> | cut -d</span><span class=\"mtk8\">&#39;&quot;&#39;</span><span class=\"mtk1\"> -f2 | sort | uniq -c | sort -nr </span></span></span></code></pre>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 722px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ad81eeb485cd6e6246f6e1fc62822c95/ad973/invalid_pipeline.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 257.29166666666663%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAzCAYAAACXICiDAAAACXBIWXMAABYlAAAWJQFJUiTwAAACL0lEQVRYw+VXa4+bMBA0AZrcmTd5kgfCgCGQcHfq//9tU63TXnq5REXqVqp0H1YC2Yx22RmPVyTpHFW2Rh0HOK4XGHYbtMsUeznDyz5DEXrQ8xhv+Q5FIBE/PyGMIsRxjCiKIIT4GHE6x1bOYN8u3Ana813laLoOfdehaZr7gIdAwqUXy4JlWdfFm2fac95nUHWNuqpwOBzuA+59CWdEhrRnOGxRag1d19hut0yAtTblFkXBA1hpjaqqoJTCdDrlAGxQliW6roPv+0yASuF8PiMIAr4M27blBaSSP5H7bwCPxyNXhhpVWRrqeJ7H15TT6WQ0zcZDrTUXDy+AdV1jNpvxlKxUgWEYkCQJb5f5lPKT2FLKLyM9pcw//F+l1xjpEbFZpdf3/TjpTS0LC8fGyrER2ZOHGZJaRknvHdC1kTj2Q+lRsEmPSmaU3uU8JB4yNeUKyCe9sjQHLLsFsAJSyWEY8gIynYdXC2Btymjpjbkf0oWTQF3X5Sq5NNc5PtcrCsNDRtdT5jxkdL0LIKvr0XWO0fWU4SGr61HJTNL7B00hLROxWV2PfPmh9NwRgO5NhjRJ/VLK+4xIgDtfwho5jb7kezM8al3fHx6jdG7m4NQS8CcCwZ0IJwJSCPhCoN+s0HQ9jm1rSl6v1wY4z3OkaQqRJCm86TfzwbP1OaQl8CQEFp5EuVmhzHP0p5OhC3WYtLxcLpFl2YVChGo7zh/LTRcLDK9v0E1jvOTDXP1b/AAcNHMKJtnWvwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/ad81eeb485cd6e6246f6e1fc62822c95/a59e9/invalid_pipeline.webp 192w,\n/static/ad81eeb485cd6e6246f6e1fc62822c95/0ca9f/invalid_pipeline.webp 384w,\n/static/ad81eeb485cd6e6246f6e1fc62822c95/6aa51/invalid_pipeline.webp 722w\"\n              sizes=\"(max-width: 722px) 100vw, 722px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/ad81eeb485cd6e6246f6e1fc62822c95/3b721/invalid_pipeline.png 192w,\n/static/ad81eeb485cd6e6246f6e1fc62822c95/66595/invalid_pipeline.png 384w,\n/static/ad81eeb485cd6e6246f6e1fc62822c95/ad973/invalid_pipeline.png 722w\"\n            sizes=\"(max-width: 722px) 100vw, 722px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/ad81eeb485cd6e6246f6e1fc62822c95/ad973/invalid_pipeline.png\"\n            alt=\"image1\"\n            title=\"image1\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>확인해보니 <strong>worker 스레드의 개수가 거의 50</strong>개로 비정상적으로 많은 부분을 확인할 수 있었습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 768px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f4593f17d9fa27d11be720284d66fe80/1745e/valid_pipeline.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.9375%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABO0lEQVQoz3XRy3KcMBCF4Ra64LJhwJgBMzYT8EhcQsaXbPL+T/anUKWShZ3FKZU2X53ulvqQ0Rih0oo1tXy/sbQm4SER5qeOyzThvafrOvI8pyxLsixDKYWIfM6xLAhOMRphcYrVKYJVXIyw1vf8uL6yzHNEm6ah73uqqvoa29OWBZ390yg1rKlhcJpbEXx2w7quhBAI3seGO9a2Ldbar8H6kDM6xXNsmMS8WMWjFk5OM9X3zOeeIQS265UwzXF8rfV/Rj7kfLOK0w6mmjXVvNiEo5bYuhfh49Tw6+2Vn5PHPz9RH4+M4xjhT2BTHCJYJYJ3CbPT8d2xBy0RLoymurslt4ahyLhuG2/v7yzLgnMuQn+PtI+8X9iJ8GgSTlbTmCT+Y5SQyr/UWgiXCz4EzuczwzDEHW/bFnf8G5j7pAabWhR5AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/f4593f17d9fa27d11be720284d66fe80/a59e9/valid_pipeline.webp 192w,\n/static/f4593f17d9fa27d11be720284d66fe80/0ca9f/valid_pipeline.webp 384w,\n/static/f4593f17d9fa27d11be720284d66fe80/dc9b9/valid_pipeline.webp 768w,\n/static/f4593f17d9fa27d11be720284d66fe80/b22d3/valid_pipeline.webp 814w\"\n              sizes=\"(max-width: 768px) 100vw, 768px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/f4593f17d9fa27d11be720284d66fe80/3b721/valid_pipeline.png 192w,\n/static/f4593f17d9fa27d11be720284d66fe80/66595/valid_pipeline.png 384w,\n/static/f4593f17d9fa27d11be720284d66fe80/fe486/valid_pipeline.png 768w,\n/static/f4593f17d9fa27d11be720284d66fe80/1745e/valid_pipeline.png 814w\"\n            sizes=\"(max-width: 768px) 100vw, 768px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/f4593f17d9fa27d11be720284d66fe80/fe486/valid_pipeline.png\"\n            alt=\"image2\"\n            title=\"image2\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>정상적인 logstash는 위와 같이 <strong>파이프라인당 스레드를 2~3개</strong> 정도만 사용중이어서 이상함을 느꼈고 logstash 코드를 뒤지기 시작했습니다.</p>\n<p>logstash(7.17.5 버전) 코드를 뒤져서 확인해보니 <code class=\"language-text\">pipeline.workers</code>로 스레드를 설정하는 코드를 발견할 수 있었습니다.</p>\n<p><a href=\"https://github.com/elastic/logstash/blob/v7.17.5/logstash-core/lib/logstash/java_pipeline.rb#L92\" target=\"_blank\" rel=\"nofollow\">https://github.com/elastic/logstash/blob/v7.17.5/logstash-core/lib/logstash/java_pipeline.rb#L92</a></p>\n<p>저희의 경우 <code class=\"language-text\">pipeline.workers</code> 세팅을 안넣어주고 있었는데요, 그래서 default 옵션을 확인해보니 <strong>default로는 사용 가능한 CPU를 모두 사용</strong>하는 코드를 발견했습니다.</p>\n<p><a href=\"https://github.com/elastic/logstash/blob/v7.17.5/logstash-core/lib/logstash/environment.rb#L56\" target=\"_blank\" rel=\"nofollow\">https://github.com/elastic/logstash/blob/v7.17.5/logstash-core/lib/logstash/environment.rb#L56</a></p>\n<p>알고보니 cgroup 이슈로 저희가 설정한 CPU (1500Mi)를 찾을 수 없어 노드 전체 CPU(48core)로 사용 가능한 CPU를 잡아버렸고, <strong>스레드 수도 사용 가능한 CPU 수 만큼 생겼던 것입니다.</strong></p>\n<p>때문에 <strong>스레드 수가 파이프라인당 거의 50개씩 추가되고 있어서 OOM</strong>이 발생했던 것이었습니다.</p>\n<h2>해결</h2>\n<p>해결방법은 아주 간단한데요, pipeline.workers를 고정해주거나 logstash의 JDK 버전을 올려 cgroup v2를 지원해주도록 하면 됩니다.</p>\n<p>이 트러블 슈팅은 해결방법보단 그 과정에서 의미가 있었는데요, <a href=\"https://gusah009.github.io/infra/2024-04-23-k8s%EC%97%90%EC%84%9C%20%EA%B5%AC%EB%B2%84%EC%A0%84%20jdk%EC%9D%98%20heap%20size%20%EC%84%A4%EC%A0%95%EC%9D%B4%20%EC%9D%B4%EC%83%81%ED%95%9C%20%EC%9D%B4%EC%8A%88/\" target=\"_blank\" rel=\"nofollow\">기존의 비슷한 이슈</a>를 먼저 깊게 파보지 않았다면 원인 파악을 위해 빙빙 돌았을 수도 있습니다.</p>\n<p>하지만 <strong>기존에 문제를 깊게 파보고 원인을 명확히 했던 덕분에</strong> 이번 이슈는 <strong>꽤 빠른 시간에 원인을 확인</strong>했다는 점에서 의미가 있다고 볼 수 있습니다.</p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .default-dark {\n    background-color: #1E1E1E;\n    color: #D4D4D4;\n  }\n  .default-dark .mtk1 { color: #D4D4D4; }\n  .default-dark .mtk3 { color: #6A9955; }\n  .default-dark .mtk8 { color: #CE9178; }\n  .default-dark .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","frontmatter":{"title":"logstash OOM 트러블슈팅","summary":"오늘은 jdk11을 사용하는 logstash에서 발생한 OOM 이슈를 트러블슈팅한 경험에 대해 공유하겠습니다","date":"2025.04.01.","categories":["Infra"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABsklEQVQoz52STUhUcRTFf+89PzDCGBAikCE1P1JHHVCbdLQigpCC2rQa8eOJM46OM4pBCgMiEWFiszJa1aJtuYsgyEW0ayO0EaPkvf//+YkIgaO0+MuTEUREGA8czl1cLufecyk3beoGhBZISCOQkHp1v6Cyz8Y/JPDHHLJGTVjoBH/j7bQoDlkopSg3LS3l6uOP2Q90HVGzdOFarx0t7bYevf/6j5Kuv3gfzmvAETlWn0XwD4rW9jHHMl9vqtD0hgok5Lf6yIrncvAV50KFab+deLetFhZ30wuLu/+fvFhXxSHrAXDHyC/0AZVAJ1ACXAfqXR9AKRAE2oAyd1kgl8aY/DH7aUf9XN7b+/4rnY7Nbaqq8FYS6NX0vGlgEpgFUsAMEAdGgDfAFPAceAm4K3kp67FDHck1lZrfUZMftlVzXG5V9VkV+0qRe/HKJaAI8AAFGTUyLDxGT6Yvh5ZRx3U56ouILw1R8bkhKm7XDdiYUmlaTkH2N+xIrmk34pKrXRa1YeH+JL6I0A9jNfI5JemTOPEN9/9w66mj3322qt8bXzWahqV+c8QhkJD4B2XWDg8APkmTYvd/6agAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/6d2bac6b3961b2da6af255d75e4bcdd8/5816c/kubernetes_logo_icon_168360.png","srcSet":"/static/6d2bac6b3961b2da6af255d75e4bcdd8/fbd2a/kubernetes_logo_icon_168360.png 125w,\n/static/6d2bac6b3961b2da6af255d75e4bcdd8/64de5/kubernetes_logo_icon_168360.png 250w,\n/static/6d2bac6b3961b2da6af255d75e4bcdd8/5816c/kubernetes_logo_icon_168360.png 499w","sizes":"(min-width: 499px) 499px, 100vw"},"sources":[{"srcSet":"/static/6d2bac6b3961b2da6af255d75e4bcdd8/a32ff/kubernetes_logo_icon_168360.webp 125w,\n/static/6d2bac6b3961b2da6af255d75e4bcdd8/62fc2/kubernetes_logo_icon_168360.webp 250w,\n/static/6d2bac6b3961b2da6af255d75e4bcdd8/4c7fb/kubernetes_logo_icon_168360.webp 499w","type":"image/webp","sizes":"(min-width: 499px) 499px, 100vw"}]},"width":499,"height":256}},"publicURL":"/static/6d2bac6b3961b2da6af255d75e4bcdd8/kubernetes_logo_icon_168360.png"}}}}]}},"pageContext":{"slug":"/infra/2025-04-01-logstash OOM/"}},"staticQueryHashes":["2518467932","429584967"]}